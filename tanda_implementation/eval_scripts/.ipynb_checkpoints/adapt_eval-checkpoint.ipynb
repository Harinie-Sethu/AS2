{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f06977b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19bf4e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4def1694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/scratch/kapilrk04/cache'\n",
    "os.environ['HF_DATASETS_CACHE']=\"/scratch/kapilrk04/cache\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52b90042",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "047294670009488290cf43cae09d869a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c7f3d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72fdfbc0c0e4405fb00b802f53547e7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/3.79k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8680b6bfd514b6f92724a508b4ff822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/1.77k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd49d3f8bcd44685a21d095d8f12c8b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/13.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset wiki_qa/default to /scratch/kapilrk04/cache/wiki_qa/default/0.1.0/d2d236b5cbdc6fbdab45d168b4d678a002e06ddea3525733a24558150585951c...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd68c7528c924e2b851cd49789be01a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/7.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/6165 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/2733 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/20360 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset wiki_qa downloaded and prepared to /scratch/kapilrk04/cache/wiki_qa/default/0.1.0/d2d236b5cbdc6fbdab45d168b4d678a002e06ddea3525733a24558150585951c. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30d0acd73a84440b929af8f9e6626da7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'question_id': ['Q1', 'Q1', 'Q1', 'Q1', 'Q1'],\n",
       " 'question': ['how are glacier caves formed?',\n",
       "  'how are glacier caves formed?',\n",
       "  'how are glacier caves formed?',\n",
       "  'how are glacier caves formed?',\n",
       "  'how are glacier caves formed?'],\n",
       " 'document_title': ['Glacier cave',\n",
       "  'Glacier cave',\n",
       "  'Glacier cave',\n",
       "  'Glacier cave',\n",
       "  'Glacier cave'],\n",
       " 'answer': ['A partly submerged glacier cave on Perito Moreno Glacier .',\n",
       "  'The ice facade is approximately 60 m high',\n",
       "  'Ice formations in the Titlis glacier cave',\n",
       "  'A glacier cave is a cave formed within the ice of a glacier .',\n",
       "  'Glacier caves are often called ice caves , but this term is properly used to describe bedrock caves that contain year-round ice.'],\n",
       " 'label': [0, 0, 0, 1, 0]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "wiki_qa_dataset = load_dataset(\"wiki_qa\")\n",
    "\n",
    "wiki_qa_dataset[\"train\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9110881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_qa_set = {\n",
    "    \"train\" : {},\n",
    "    \"validation\" : {},\n",
    "    \"test\" : {}\n",
    "}\n",
    "\n",
    "for split in [\"train\", \"validation\", \"test\"]:\n",
    "    for example in wiki_qa_dataset[split]:\n",
    "        if example[\"question_id\"] not in wiki_qa_set[split]:\n",
    "            wiki_qa_set[split][example[\"question_id\"]] = {\n",
    "                \"question\" : example[\"question\"],\n",
    "                \"answers\" : [],\n",
    "                \"labels\" : [],\n",
    "                \"sum_labels\" : 0\n",
    "            }\n",
    "        wiki_qa_set[split][example[\"question_id\"]][\"answers\"].append(example[\"answer\"])\n",
    "        wiki_qa_set[split][example[\"question_id\"]][\"labels\"].append(example[\"label\"])\n",
    "        wiki_qa_set[split][example[\"question_id\"]][\"sum_labels\"] += example[\"label\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92b49de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "wiki_qa_trainp = [{\"sentence1\" : wiki_qa_set[\"train\"][qn][\"question\"], \"sentence2\" : wiki_qa_set[\"train\"][qn][\"answers\"][i], \"label\" : wiki_qa_set[\"train\"][qn][\"labels\"][i]} for qn in wiki_qa_set[\"train\"] for i in range(len(wiki_qa_set[\"train\"][qn][\"answers\"])) if wiki_qa_set[\"train\"][qn][\"sum_labels\"] > 0 and wiki_qa_set[\"train\"][qn][\"sum_labels\"] < len(wiki_qa_set[\"train\"][qn][\"labels\"])]\n",
    "wiki_qa_validationp = [{\"sentence1\" : wiki_qa_set[\"validation\"][qn][\"question\"], \"sentence2\" : wiki_qa_set[\"validation\"][qn][\"answers\"][i], \"label\" : wiki_qa_set[\"validation\"][qn][\"labels\"][i]} for qn in wiki_qa_set[\"validation\"] for i in range(len(wiki_qa_set[\"validation\"][qn][\"answers\"])) if wiki_qa_set[\"validation\"][qn][\"sum_labels\"] > 0 and wiki_qa_set[\"validation\"][qn][\"sum_labels\"] < len(wiki_qa_set[\"validation\"][qn][\"labels\"])]\n",
    "wiki_qa_testp = [{\"sentence1\" : wiki_qa_set[\"test\"][qn][\"question\"], \"sentence2\" : wiki_qa_set[\"test\"][qn][\"answers\"][i], \"label\" : wiki_qa_set[\"test\"][qn][\"labels\"][i]} for qn in wiki_qa_set[\"test\"] for i in range(len(wiki_qa_set[\"test\"][qn][\"answers\"])) if wiki_qa_set[\"test\"][qn][\"sum_labels\"] > 0 and wiki_qa_set[\"test\"][qn][\"sum_labels\"] < len(wiki_qa_set[\"test\"][qn][\"labels\"])]\n",
    "\n",
    "wiki_qa_trainp = pd.DataFrame(wiki_qa_trainp)\n",
    "wiki_qa_validationp = pd.DataFrame(wiki_qa_validationp)\n",
    "wiki_qa_testp = pd.DataFrame(wiki_qa_testp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7274d663",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_qa_trainp['idx'] = range(1, len(wiki_qa_trainp)+1)\n",
    "wiki_qa_validationp['idx'] = range(1, len(wiki_qa_validationp)+1)\n",
    "wiki_qa_testp['idx'] = range(1, len(wiki_qa_testp)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3d98af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11920/4233327953.py:1: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  pd.value_counts(wiki_qa_trainp[\"label\"])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    7632\n",
       "1    1019\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(wiki_qa_trainp[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cda3cb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11920/563605948.py:1: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  pd.value_counts(wiki_qa_testp[\"label\"])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    2058\n",
       "1     283\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(wiki_qa_testp[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d0ec5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11920/3341298044.py:1: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  pd.value_counts(wiki_qa_validationp[\"label\"])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    990\n",
       "1    136\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(wiki_qa_validationp[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "618cb246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8651 2341 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/kapilrk04/anaconda3/lib/python3.11/site-packages/pyarrow/pandas_compat.py:373: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if _pandas_api.is_sparse(col):\n"
     ]
    }
   ],
   "source": [
    "wiki_train_ds = Dataset.from_pandas(wiki_qa_trainp)\n",
    "wiki_test_ds = Dataset.from_pandas(wiki_qa_testp)\n",
    "wiki_valid_ds = Dataset.from_pandas(wiki_qa_validationp)\n",
    "\n",
    "print(len(wiki_train_ds), len(wiki_test_ds), len(wiki_valid_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35775651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "    num_rows: 8651\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc1f443f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"distilbert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c57d51d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoints = {\n",
    "    \"distilbert-base-uncased\": \"/scratch/kapilrk04/best-distilbert/checkpoint-21468\",\n",
    "    \"roberta-base\": \"/scratch/kapilrk04/best-roberta/checkpoint-21468\",\n",
    "    \"bert-base-uncased\": \"/scratch/kapilrk04/best-bert/checkpoint-37569\",\n",
    "    \"albert-base-v2\": \"/scratch/kapilrk04/best-albert/checkpoint-16101\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42a0a417",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ca11d081b2d4a428470156c815498ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'model_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer\n\u001b[0;32m----> 3\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_checkpoints[model_name], use_fast\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_name' is not defined"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoints[model_name], use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d0a7b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"sentence1\"], examples[\"sentence2\"], truncation=True)\n",
    "\n",
    "# encoded_train_dataset = wiki_train_ds.map(preprocess_function, batched=True)\n",
    "# encoded_dev_dataset = wiki_valid_ds.map(preprocess_function, batched=True)\n",
    "# encoded_test_dataset = wiki_test_ds.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b031f93b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[SEP]'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('SEP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd2914c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_array_by_number(arr, number):\n",
    "    result = []\n",
    "    current_split = []\n",
    "    \n",
    "    for item in arr:\n",
    "        if item == number:\n",
    "            if current_split:\n",
    "                result.append(current_split)\n",
    "                return current_split\n",
    "        else:\n",
    "            current_split.append(item)\n",
    "    if current_split:\n",
    "        result.append(current_split)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f0b5766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels, inputs = eval_pred\n",
    "    \n",
    "    splitnum = 0\n",
    "    if model_name == \"roberta-base\":\n",
    "        splitnum = 2\n",
    "    elif model_name == \"bert-base-uncased\":\n",
    "        splitnum = 102\n",
    "    elif model_name == \"albert-base-v2\":\n",
    "        splitnum = 3\n",
    "    elif model_name == \"distilbert-base-uncased\":\n",
    "        splitnum = 102\n",
    "\n",
    "    per_qn_inputs = {}\n",
    "\n",
    "    for i in range(len(inputs)):\n",
    "        split_inputs = split_array_by_number(inputs[i], splitnum)\n",
    "        qn = tuple(split_inputs)\n",
    "        if qn not in per_qn_inputs:\n",
    "            per_qn_inputs[qn] = {}\n",
    "            per_qn_inputs[qn][\"predictions\"] = []\n",
    "            per_qn_inputs[qn][\"labels\"] = []\n",
    "            per_qn_inputs[qn][\"sum_labels\"] = 0\n",
    "        per_qn_inputs[qn][\"predictions\"].append(predictions[i])\n",
    "        per_qn_inputs[qn][\"labels\"].append(labels[i])\n",
    "        per_qn_inputs[qn][\"sum_labels\"] += labels[i]\n",
    "\n",
    "    avg_prec_scores = []\n",
    "    enc = OneHotEncoder(sparse=False)\n",
    "    labels = enc.fit_transform(np.array(labels).reshape(-1,1))\n",
    "\n",
    "    reciprocal_ranks = []\n",
    "\n",
    "    for qn in per_qn_inputs:\n",
    "        if per_qn_inputs[qn][\"sum_labels\"] == 0 or per_qn_inputs[qn][\"sum_labels\"] == len(per_qn_inputs[qn][\"labels\"]):\n",
    "            continue\n",
    "        per_qn_inputs[qn]['predictions'] = np.array(per_qn_inputs[qn]['predictions'])\n",
    "        per_qn_inputs[qn]['labels'] = enc.fit_transform(np.array(per_qn_inputs[qn]['labels']).reshape(-1,1))\n",
    "\n",
    "        #print(per_qn_inputs[qn]['predictions'], per_qn_inputs[qn]['labels'])\n",
    "        avg_prec_scores.append(average_precision_score(per_qn_inputs[qn][\"labels\"], per_qn_inputs[qn][\"predictions\"]))\n",
    "\n",
    "        true_label = per_qn_inputs[qn][\"labels\"]\n",
    "        pred_label = per_qn_inputs[qn][\"predictions\"]\n",
    "\n",
    "        sorted_pred_label = np.argsort(pred_label)[::-1]\n",
    "\n",
    "        for j in range(len(sorted_pred_label)):\n",
    "            row = sorted_pred_label[j]\n",
    "            rank = np.where(row == 1)[0]\n",
    "            if rank.size > 0:\n",
    "                reciprocal_ranks.append(1/(rank[0]+1))\n",
    "                break\n",
    "    \n",
    "    \n",
    "    map_score = np.mean(avg_prec_scores)\n",
    "    mrr_score = np.mean(reciprocal_ranks)\n",
    "\n",
    "    return {\n",
    "        \"mAP\" : map_score,\n",
    "        \"mRR\" : mrr_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c087559",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoints[model_name], num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4244c7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba2c7c1",
   "metadata": {},
   "source": [
    "## For WikiQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8232609d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "\n",
    "args1 = TrainingArguments(\n",
    "    output_dir=f\"/scratch/kapilrk04/{model_name}_adapt_model_wikiqa\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=1e-6,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    include_inputs_for_metrics = True,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    fp16=False,\n",
    "    report_to=\"wandb\",\n",
    "    run_name=f\"tanda-{model_name}-eval-wikiqa\"\n",
    ")\n",
    "\n",
    "trainer1 = Trainer(\n",
    "    model,\n",
    "    args1,\n",
    "    train_dataset=encoded_train_dataset,\n",
    "    eval_dataset=encoded_dev_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer2 = Trainer(\n",
    "    model,\n",
    "    args1,\n",
    "    train_dataset=encoded_train_dataset,\n",
    "    eval_dataset=encoded_test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0de50855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fa56bf",
   "metadata": {},
   "source": [
    "### DISTILBERT\n",
    "\n",
    "#### Evaluation without Adapt Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e98fdf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='294' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [147/147 04:37]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkapilrk-04\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home2/kapilrk04/anlp_proj/eval_scripts/wandb/run-20231101_175437-2dywn4x1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kapilrk-04/huggingface/runs/2dywn4x1' target=\"_blank\">tanda-distilbert-base-uncased-eval-wikiqa</a></strong> to <a href='https://wandb.ai/kapilrk-04/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kapilrk-04/huggingface' target=\"_blank\">https://wandb.ai/kapilrk-04/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kapilrk-04/huggingface/runs/2dywn4x1' target=\"_blank\">https://wandb.ai/kapilrk-04/huggingface/runs/2dywn4x1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.2540453672409058,\n",
       " 'eval_mAP': 0.8247626132003596,\n",
       " 'eval_mRR': 0.8164556962025317,\n",
       " 'eval_runtime': 14.942,\n",
       " 'eval_samples_per_second': 156.672,\n",
       " 'eval_steps_per_second': 9.838}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer2.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752dc8a9",
   "metadata": {},
   "source": [
    "### Adapt Step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f5ae877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1623' max='1623' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1623/1623 03:39, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Map</th>\n",
       "      <th>Mrr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.488800</td>\n",
       "      <td>0.388807</td>\n",
       "      <td>0.849169</td>\n",
       "      <td>0.963115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.308600</td>\n",
       "      <td>0.306936</td>\n",
       "      <td>0.869711</td>\n",
       "      <td>0.959016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.268400</td>\n",
       "      <td>0.293716</td>\n",
       "      <td>0.875472</td>\n",
       "      <td>0.963115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1623, training_loss=0.34898977931898756, metrics={'train_runtime': 219.931, 'train_samples_per_second': 118.005, 'train_steps_per_second': 7.38, 'total_flos': 481072175369484.0, 'train_loss': 0.34898977931898756, 'epoch': 3.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer1.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24925256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.29627764225006104,\n",
       " 'eval_mAP': 0.8762934337851589,\n",
       " 'eval_mRR': 0.9725738396624473,\n",
       " 'eval_runtime': 8.8906,\n",
       " 'eval_samples_per_second': 263.311,\n",
       " 'eval_steps_per_second': 16.534}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer2.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbebd10",
   "metadata": {},
   "source": [
    "### RoBERTa\n",
    "\n",
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "473eccd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8651 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1126 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2341 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"roberta-base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoints[model_name], use_fast=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoints[model_name], num_labels=2)\n",
    "\n",
    "encoded_train_dataset = wiki_train_ds.map(preprocess_function, batched=True)\n",
    "encoded_dev_dataset = wiki_valid_ds.map(preprocess_function, batched=True)\n",
    "encoded_test_dataset = wiki_test_ds.map(preprocess_function, batched=True)\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "args1 = TrainingArguments(\n",
    "    output_dir=f\"/scratch/kapilrk04/{model_name}_adapt_model_wikiqa\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=1e-6,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    include_inputs_for_metrics = True,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    fp16=False,\n",
    "    report_to=\"wandb\",\n",
    "    run_name=f\"tanda-{model_name}-eval-wikiqa\"\n",
    ")\n",
    "\n",
    "trainer1 = Trainer(\n",
    "    model,\n",
    "    args1,\n",
    "    train_dataset=encoded_train_dataset,\n",
    "    eval_dataset=encoded_dev_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer2 = Trainer(\n",
    "    model,\n",
    "    args1,\n",
    "    train_dataset=encoded_train_dataset,\n",
    "    eval_dataset=encoded_test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "032347cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='294' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [147/147 08:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkapilrk-04\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home2/kapilrk04/anlp_proj/eval_scripts/wandb/run-20231101_185301-pshx364r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kapilrk-04/huggingface/runs/pshx364r' target=\"_blank\">tanda-roberta-base-eval-wikiqa</a></strong> to <a href='https://wandb.ai/kapilrk-04/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kapilrk-04/huggingface' target=\"_blank\">https://wandb.ai/kapilrk-04/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kapilrk-04/huggingface/runs/pshx364r' target=\"_blank\">https://wandb.ai/kapilrk-04/huggingface/runs/pshx364r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5455897450447083,\n",
       " 'eval_mAP': 0.8748434525181479,\n",
       " 'eval_mRR': 0.8670886075949367,\n",
       " 'eval_runtime': 15.7099,\n",
       " 'eval_samples_per_second': 149.014,\n",
       " 'eval_steps_per_second': 9.357}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer2.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f265b713",
   "metadata": {},
   "source": [
    "### Adapt Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0b503c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1623' max='1623' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1623/1623 07:09, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Map</th>\n",
       "      <th>Mrr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.259800</td>\n",
       "      <td>0.266859</td>\n",
       "      <td>0.895401</td>\n",
       "      <td>0.971311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.221100</td>\n",
       "      <td>0.254539</td>\n",
       "      <td>0.900199</td>\n",
       "      <td>0.967213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.206100</td>\n",
       "      <td>0.254204</td>\n",
       "      <td>0.905442</td>\n",
       "      <td>0.963115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1623, training_loss=0.2264632156287456, metrics={'train_runtime': 429.9456, 'train_samples_per_second': 60.363, 'train_steps_per_second': 3.775, 'total_flos': 973207196563020.0, 'train_loss': 0.2264632156287456, 'epoch': 3.0})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer1.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "02cfaaf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.2270554155111313,\n",
       " 'eval_mAP': 0.9129163265724768,\n",
       " 'eval_mRR': 0.9472573839662447,\n",
       " 'eval_runtime': 15.5035,\n",
       " 'eval_samples_per_second': 150.998,\n",
       " 'eval_steps_per_second': 9.482}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer2.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18afbdbc",
   "metadata": {},
   "source": [
    "### BERT-base\n",
    "\n",
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4c7a6d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8651 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1126 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2341 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoints[model_name], use_fast=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoints[model_name], num_labels=2)\n",
    "\n",
    "encoded_train_dataset = wiki_train_ds.map(preprocess_function, batched=True)\n",
    "encoded_dev_dataset = wiki_valid_ds.map(preprocess_function, batched=True)\n",
    "encoded_test_dataset = wiki_test_ds.map(preprocess_function, batched=True)\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "args1 = TrainingArguments(\n",
    "    output_dir=f\"/scratch/kapilrk04/{model_name}_adapt_model_wikiqa\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=1e-6,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    include_inputs_for_metrics = True,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    fp16=False,\n",
    "    report_to=\"wandb\",\n",
    "    run_name=f\"tanda-{model_name}-eval-wikiqa\"\n",
    ")\n",
    "\n",
    "trainer1 = Trainer(\n",
    "    model,\n",
    "    args1,\n",
    "    train_dataset=encoded_train_dataset,\n",
    "    eval_dataset=encoded_dev_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer2 = Trainer(\n",
    "    model,\n",
    "    args1,\n",
    "    train_dataset=encoded_train_dataset,\n",
    "    eval_dataset=encoded_test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e78fdd",
   "metadata": {},
   "source": [
    "#### Evaluation without adapt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "86ce7c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='294' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [147/147 13:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.206527590751648,\n",
       " 'eval_mAP': 0.8840168712540487,\n",
       " 'eval_mRR': 0.8523206751054853,\n",
       " 'eval_runtime': 14.144,\n",
       " 'eval_samples_per_second': 165.511,\n",
       " 'eval_steps_per_second': 10.393}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer2.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924d099a",
   "metadata": {},
   "source": [
    "### Adapt Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7faa9ea6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1623' max='1623' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1623/1623 06:25, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Map</th>\n",
       "      <th>Mrr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.588300</td>\n",
       "      <td>0.443045</td>\n",
       "      <td>0.866382</td>\n",
       "      <td>0.938525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.321700</td>\n",
       "      <td>0.352069</td>\n",
       "      <td>0.868376</td>\n",
       "      <td>0.946721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.267300</td>\n",
       "      <td>0.338181</td>\n",
       "      <td>0.871768</td>\n",
       "      <td>0.946721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1623, training_loss=0.38305452761647146, metrics={'train_runtime': 385.4473, 'train_samples_per_second': 67.332, 'train_steps_per_second': 4.211, 'total_flos': 955521200310540.0, 'train_loss': 0.38305452761647146, 'epoch': 3.0})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer1.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "18c3337c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.27525728940963745,\n",
       " 'eval_mAP': 0.9039335688723785,\n",
       " 'eval_mRR': 0.9641350210970464,\n",
       " 'eval_runtime': 14.3882,\n",
       " 'eval_samples_per_second': 162.703,\n",
       " 'eval_steps_per_second': 10.217}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer2.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e1d0b4",
   "metadata": {},
   "source": [
    "### ALBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2627ab28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8651 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1126 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2341 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"albert-base-v2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoints[model_name], use_fast=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoints[model_name], num_labels=2)\n",
    "\n",
    "encoded_train_dataset = wiki_train_ds.map(preprocess_function, batched=True)\n",
    "encoded_dev_dataset = wiki_valid_ds.map(preprocess_function, batched=True)\n",
    "encoded_test_dataset = wiki_test_ds.map(preprocess_function, batched=True)\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "args1 = TrainingArguments(\n",
    "    output_dir=f\"/scratch/kapilrk04/{model_name}_adapt_model_wikiqa\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=1e-6,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    include_inputs_for_metrics = True,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    fp16=False,\n",
    "    report_to=\"wandb\",\n",
    "    run_name=f\"tanda-{model_name}-eval-wikiqa\"\n",
    ")\n",
    "\n",
    "trainer1 = Trainer(\n",
    "    model,\n",
    "    args1,\n",
    "    train_dataset=encoded_train_dataset,\n",
    "    eval_dataset=encoded_dev_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer2 = Trainer(\n",
    "    model,\n",
    "    args1,\n",
    "    train_dataset=encoded_train_dataset,\n",
    "    eval_dataset=encoded_test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9250d229",
   "metadata": {},
   "source": [
    "#### Evaluation without adapt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8bef9811",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a AlbertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='294' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [147/147 04:42]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.44269248843193054,\n",
       " 'eval_mAP': 0.8947844653714525,\n",
       " 'eval_mRR': 0.8818565400843882,\n",
       " 'eval_runtime': 5.2945,\n",
       " 'eval_samples_per_second': 442.161,\n",
       " 'eval_steps_per_second': 27.765}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer2.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2041805b",
   "metadata": {},
   "source": [
    "#### ADAPT then eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fca1cb3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1623' max='1623' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1623/1623 02:10, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Map</th>\n",
       "      <th>Mrr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.255900</td>\n",
       "      <td>0.252917</td>\n",
       "      <td>0.881361</td>\n",
       "      <td>0.971311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.207400</td>\n",
       "      <td>0.248619</td>\n",
       "      <td>0.891933</td>\n",
       "      <td>0.971311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.192200</td>\n",
       "      <td>0.248872</td>\n",
       "      <td>0.893031</td>\n",
       "      <td>0.971311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1623, training_loss=0.21701622479357105, metrics={'train_runtime': 130.6803, 'train_samples_per_second': 198.599, 'train_steps_per_second': 12.42, 'total_flos': 91942672135860.0, 'train_loss': 0.21701622479357105, 'epoch': 3.0})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer1.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "143b0cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.22224316000938416,\n",
       " 'eval_mAP': 0.9169585395748496,\n",
       " 'eval_mRR': 0.9725738396624473,\n",
       " 'eval_runtime': 5.2803,\n",
       " 'eval_samples_per_second': 443.343,\n",
       " 'eval_steps_per_second': 27.839}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer2.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fdf661",
   "metadata": {},
   "source": [
    "## For TrecQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6fc63e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>who is the author of the book , `` the iron la...</td>\n",
       "      <td>the iron lady ; a biography of margaret thatch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>who is the author of the book , `` the iron la...</td>\n",
       "      <td>in this same revisionist mold , hugo young , t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>who is the author of the book , `` the iron la...</td>\n",
       "      <td>in `` the iron lady , '' young traces the wind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>who is the author of the book , `` the iron la...</td>\n",
       "      <td>`` he is the very essence of the classless mer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>who is the author of the book , `` the iron la...</td>\n",
       "      <td>from her father , young argues , she inherited...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                          sentence1  \\\n",
       "0      1  who is the author of the book , `` the iron la...   \n",
       "1      1  who is the author of the book , `` the iron la...   \n",
       "2      1  who is the author of the book , `` the iron la...   \n",
       "3      1  who is the author of the book , `` the iron la...   \n",
       "4      0  who is the author of the book , `` the iron la...   \n",
       "\n",
       "                                           sentence2  \n",
       "0  the iron lady ; a biography of margaret thatch...  \n",
       "1  in this same revisionist mold , hugo young , t...  \n",
       "2  in `` the iron lady , '' young traces the wind...  \n",
       "3  `` he is the very essence of the classless mer...  \n",
       "4  from her father , young argues , she inherited...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trecqa_train = pd.read_csv(\"/home2/kapilrk04/anlp_proj/data_sets/TrecQA/train.tsv\", sep=\"\\t\", names=[\"label\", \"sentence1\", \"sentence2\"])\n",
    "trecqa_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad61a2bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>what do practitioners of wicca worship ?</td>\n",
       "      <td>an estimated 50,000 americans practice wicca ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>what do practitioners of wicca worship ?</td>\n",
       "      <td>the inch- thick chaplain handbook includes a f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>what do practitioners of wicca worship ?</td>\n",
       "      <td>wicca -- sometimes spelled wycca -- comes from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>what do practitioners of wicca worship ?</td>\n",
       "      <td>ms . siefferly , a senior at the high school ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>what do practitioners of wicca worship ?</td>\n",
       "      <td>that 's because ms . palmer is a witch , the h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                 sentence1  \\\n",
       "0      1  what do practitioners of wicca worship ?   \n",
       "1      1  what do practitioners of wicca worship ?   \n",
       "2      0  what do practitioners of wicca worship ?   \n",
       "3      0  what do practitioners of wicca worship ?   \n",
       "4      0  what do practitioners of wicca worship ?   \n",
       "\n",
       "                                           sentence2  \n",
       "0  an estimated 50,000 americans practice wicca ,...  \n",
       "1  the inch- thick chaplain handbook includes a f...  \n",
       "2  wicca -- sometimes spelled wycca -- comes from...  \n",
       "3  ms . siefferly , a senior at the high school ,...  \n",
       "4  that 's because ms . palmer is a witch , the h...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trecqa_test = pd.read_csv(\"/home2/kapilrk04/anlp_proj/data_sets/TrecQA/test.tsv\", sep=\"\\t\", names=[\"label\", \"sentence1\", \"sentence2\"])\n",
    "trecqa_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "900ce75e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>what is crips ' gang color ?</td>\n",
       "      <td>prosecutors said the '' rampage of murder and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>what is crips ' gang color ?</td>\n",
       "      <td>two men were convicted monday of abducting and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>what is crips ' gang color ?</td>\n",
       "      <td>prosecutors said queen , tirado and other memb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>what is crips ' gang color ?</td>\n",
       "      <td>round rock , texas _ fearful that a gang calle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>what is crips ' gang color ?</td>\n",
       "      <td>red was the gang 's color , said sherry blacke...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                     sentence1  \\\n",
       "0      1  what is crips ' gang color ?   \n",
       "1      0  what is crips ' gang color ?   \n",
       "2      0  what is crips ' gang color ?   \n",
       "3      0  what is crips ' gang color ?   \n",
       "4      0  what is crips ' gang color ?   \n",
       "\n",
       "                                           sentence2  \n",
       "0  prosecutors said the '' rampage of murder and ...  \n",
       "1  two men were convicted monday of abducting and...  \n",
       "2  prosecutors said queen , tirado and other memb...  \n",
       "3  round rock , texas _ fearful that a gang calle...  \n",
       "4  red was the gang 's color , said sherry blacke...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trecqa_dev = pd.read_csv(\"/home2/kapilrk04/anlp_proj/data_sets/TrecQA/dev.tsv\", sep=\"\\t\", names=[\"label\", \"sentence1\", \"sentence2\"])\n",
    "trecqa_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0407461f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trecqa_train['idx'] = range(1, len(trecqa_train)+1)\n",
    "trecqa_dev['idx'] = range(1, len(trecqa_dev)+1)\n",
    "trecqa_test['idx'] = range(1, len(trecqa_test)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8529c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11920/3716807603.py:1: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  pd.value_counts(trecqa_train['label'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    47014\n",
       "1     6403\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(trecqa_train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a04624f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11920/1788986853.py:1: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  pd.value_counts(trecqa_dev['label'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    912\n",
       "1    205\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(trecqa_dev['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fe00f3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11920/959730337.py:1: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  pd.value_counts(trecqa_test['label'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    1194\n",
       "1     248\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(trecqa_test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38cd26d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trecqa_train_ds = Dataset.from_pandas(trecqa_train)\n",
    "trecqa_test_ds = Dataset.from_pandas(trecqa_test)\n",
    "trecqa_valid_ds = Dataset.from_pandas(trecqa_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a3bc75ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/53417 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1442 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1117 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_trecqa_train_ds = trecqa_train_ds.map(preprocess_function, batched=True)\n",
    "encoded_trecqa_test_ds = trecqa_test_ds.map(preprocess_function, batched=True)\n",
    "encoded_trecqa_valid_ds = trecqa_valid_ds.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56c1833",
   "metadata": {},
   "source": [
    "### DISTILBert "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "979a240a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/53417 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1442 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1117 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"distilbert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoints[model_name], use_fast=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoints[model_name], num_labels=2)\n",
    "\n",
    "encoded_trecqa_train_ds = trecqa_train_ds.map(preprocess_function, batched=True)\n",
    "encoded_trecqa_test_ds = trecqa_test_ds.map(preprocess_function, batched=True)\n",
    "encoded_trecqa_valid_ds = trecqa_valid_ds.map(preprocess_function, batched=True)\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "args2 = TrainingArguments(\n",
    "    output_dir=f\"/scratch/kapilrk04/{model_name}_adapt_model_trecqa\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=1e-6,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    include_inputs_for_metrics = True,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    fp16=False,\n",
    "    report_to=\"wandb\",\n",
    "    run_name=f\"tanda-{model_name}-eval-trecqa\"\n",
    ")\n",
    "\n",
    "trainer1 = Trainer(\n",
    "    model,\n",
    "    args2,\n",
    "    train_dataset=encoded_trecqa_train_ds,\n",
    "    eval_dataset=encoded_trecqa_valid_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer2 = Trainer(\n",
    "    model,\n",
    "    args2,\n",
    "    train_dataset=encoded_trecqa_train_ds,\n",
    "    eval_dataset=encoded_trecqa_test_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de691f08",
   "metadata": {},
   "source": [
    "#### Eval without Adapt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e30d767",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='182' max='91' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [91/91 21:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2562aa26f74b4f3a87915f4f568455a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112480507128769, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home2/kapilrk04/anlp_proj/eval_scripts/wandb/run-20231101_233123-mqp7nd37</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kapilrk-04/huggingface/runs/mqp7nd37' target=\"_blank\">tanda-distilbert-base-uncased-eval-trecqa</a></strong> to <a href='https://wandb.ai/kapilrk-04/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kapilrk-04/huggingface' target=\"_blank\">https://wandb.ai/kapilrk-04/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kapilrk-04/huggingface/runs/mqp7nd37' target=\"_blank\">https://wandb.ai/kapilrk-04/huggingface/runs/mqp7nd37</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.7127174139022827,\n",
       " 'eval_mAP': 0.8453589951771969,\n",
       " 'eval_mRR': 0.9191176470588235,\n",
       " 'eval_runtime': 7.3614,\n",
       " 'eval_samples_per_second': 195.886,\n",
       " 'eval_steps_per_second': 12.362}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer2.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ed90c2",
   "metadata": {},
   "source": [
    "#### Adapt and eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "538f111a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10017' max='10017' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10017/10017 20:16, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Map</th>\n",
       "      <th>Mrr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.180500</td>\n",
       "      <td>0.324770</td>\n",
       "      <td>0.908006</td>\n",
       "      <td>0.976923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.160600</td>\n",
       "      <td>0.340811</td>\n",
       "      <td>0.914059</td>\n",
       "      <td>0.976923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.157400</td>\n",
       "      <td>0.357968</td>\n",
       "      <td>0.911041</td>\n",
       "      <td>0.976923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10017, training_loss=0.1879237821814518, metrics={'train_runtime': 1216.283, 'train_samples_per_second': 131.755, 'train_steps_per_second': 8.236, 'total_flos': 3403575168829020.0, 'train_loss': 0.1879237821814518, 'epoch': 3.0})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer1.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6e0ed9b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3406190276145935,\n",
       " 'eval_mAP': 0.9213211313391761,\n",
       " 'eval_mRR': 0.9852941176470589,\n",
       " 'eval_runtime': 5.2081,\n",
       " 'eval_samples_per_second': 276.876,\n",
       " 'eval_steps_per_second': 17.473}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer2.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ffef2b",
   "metadata": {},
   "source": [
    "### RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2f7651a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/53417 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1442 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1117 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"roberta-base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoints[model_name], use_fast=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoints[model_name], num_labels=2)\n",
    "\n",
    "encoded_trecqa_train_ds = trecqa_train_ds.map(preprocess_function, batched=True)\n",
    "encoded_trecqa_test_ds = trecqa_test_ds.map(preprocess_function, batched=True)\n",
    "encoded_trecqa_valid_ds = trecqa_valid_ds.map(preprocess_function, batched=True)\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "args2 = TrainingArguments(\n",
    "    output_dir=f\"/scratch/kapilrk04/{model_name}_adapt_model_trecqa\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=1e-6,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    include_inputs_for_metrics = True,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    fp16=False,\n",
    "    report_to=\"wandb\",\n",
    "    run_name=f\"tanda-{model_name}-eval-trecqa\"\n",
    ")\n",
    "\n",
    "trainer1 = Trainer(\n",
    "    model,\n",
    "    args2,\n",
    "    train_dataset=encoded_trecqa_train_ds,\n",
    "    eval_dataset=encoded_trecqa_valid_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer2 = Trainer(\n",
    "    model,\n",
    "    args2,\n",
    "    train_dataset=encoded_trecqa_train_ds,\n",
    "    eval_dataset=encoded_trecqa_test_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191f4f68",
   "metadata": {},
   "source": [
    "#### evaluate without adapt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4b3e872d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='182' max='91' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [91/91 38:59]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.36658376455307007,\n",
       " 'eval_mAP': 0.8740550665536616,\n",
       " 'eval_mRR': 0.9191176470588235,\n",
       " 'eval_runtime': 9.5769,\n",
       " 'eval_samples_per_second': 150.571,\n",
       " 'eval_steps_per_second': 9.502}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer2.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5b75cf",
   "metadata": {},
   "source": [
    "#### adapt then evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "659149f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10017' max='10017' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10017/10017 38:40, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Map</th>\n",
       "      <th>Mrr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.152900</td>\n",
       "      <td>0.248945</td>\n",
       "      <td>0.938037</td>\n",
       "      <td>0.969231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.137600</td>\n",
       "      <td>0.268937</td>\n",
       "      <td>0.948952</td>\n",
       "      <td>0.969231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.131700</td>\n",
       "      <td>0.279227</td>\n",
       "      <td>0.949169</td>\n",
       "      <td>0.969231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10017, training_loss=0.14718421838163817, metrics={'train_runtime': 2320.9759, 'train_samples_per_second': 69.045, 'train_steps_per_second': 4.316, 'total_flos': 7224760816353660.0, 'train_loss': 0.14718421838163817, 'epoch': 3.0})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer1.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a99527aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3153335750102997,\n",
       " 'eval_mAP': 0.9319461299506272,\n",
       " 'eval_mRR': 0.9779411764705882,\n",
       " 'eval_runtime': 9.3934,\n",
       " 'eval_samples_per_second': 153.512,\n",
       " 'eval_steps_per_second': 9.688}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer2.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f943ca3a",
   "metadata": {},
   "source": [
    "### BERT-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0524bde2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/53417 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1442 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1117 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoints[model_name], use_fast=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoints[model_name], num_labels=2)\n",
    "\n",
    "encoded_trecqa_train_ds = trecqa_train_ds.map(preprocess_function, batched=True)\n",
    "encoded_trecqa_test_ds = trecqa_test_ds.map(preprocess_function, batched=True)\n",
    "encoded_trecqa_valid_ds = trecqa_valid_ds.map(preprocess_function, batched=True)\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "args2 = TrainingArguments(\n",
    "    output_dir=f\"/scratch/kapilrk04/{model_name}_adapt_model_trecqa\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=1e-6,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    include_inputs_for_metrics = True,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    fp16=False,\n",
    "    report_to=\"wandb\",\n",
    "    run_name=f\"tanda-{model_name}-eval-trecqa\"\n",
    ")\n",
    "\n",
    "trainer1 = Trainer(\n",
    "    model,\n",
    "    args2,\n",
    "    train_dataset=encoded_trecqa_train_ds,\n",
    "    eval_dataset=encoded_trecqa_valid_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer2 = Trainer(\n",
    "    model,\n",
    "    args2,\n",
    "    train_dataset=encoded_trecqa_train_ds,\n",
    "    eval_dataset=encoded_trecqa_test_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b8461d",
   "metadata": {},
   "source": [
    "#### evaluate without adapt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "66ef123c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='182' max='91' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [91/91 39:27]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.9603529572486877,\n",
       " 'eval_mAP': 0.8642261973295847,\n",
       " 'eval_mRR': 0.8970588235294118,\n",
       " 'eval_runtime': 8.5332,\n",
       " 'eval_samples_per_second': 168.986,\n",
       " 'eval_steps_per_second': 10.664}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer2.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28f8b2a",
   "metadata": {},
   "source": [
    "#### adapt then evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e9d8d9ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10017' max='10017' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10017/10017 35:14, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Map</th>\n",
       "      <th>Mrr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.166800</td>\n",
       "      <td>0.270577</td>\n",
       "      <td>0.927071</td>\n",
       "      <td>0.946154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.135100</td>\n",
       "      <td>0.282239</td>\n",
       "      <td>0.927370</td>\n",
       "      <td>0.953846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.129000</td>\n",
       "      <td>0.286719</td>\n",
       "      <td>0.927513</td>\n",
       "      <td>0.953846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10017, training_loss=0.16970100480900607, metrics={'train_runtime': 2114.8508, 'train_samples_per_second': 75.774, 'train_steps_per_second': 4.737, 'total_flos': 6760291692548700.0, 'train_loss': 0.16970100480900607, 'epoch': 3.0})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer1.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "428595e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.28860151767730713,\n",
       " 'eval_mAP': 0.9148906075181711,\n",
       " 'eval_mRR': 0.9779411764705882,\n",
       " 'eval_runtime': 8.7668,\n",
       " 'eval_samples_per_second': 164.484,\n",
       " 'eval_steps_per_second': 10.38}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer2.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7146d6",
   "metadata": {},
   "source": [
    "### ALBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1be880f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/53417 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1442 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1117 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"albert-base-v2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoints[model_name], use_fast=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoints[model_name], num_labels=2)\n",
    "\n",
    "encoded_trecqa_train_ds = trecqa_train_ds.map(preprocess_function, batched=True)\n",
    "encoded_trecqa_test_ds = trecqa_test_ds.map(preprocess_function, batched=True)\n",
    "encoded_trecqa_valid_ds = trecqa_valid_ds.map(preprocess_function, batched=True)\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "args2 = TrainingArguments(\n",
    "    output_dir=f\"/scratch/kapilrk04/{model_name}_adapt_model_trecqa\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=1e-6,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    include_inputs_for_metrics = True,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    fp16=False,\n",
    "    report_to=\"wandb\",\n",
    "    run_name=f\"tanda-{model_name}-eval-trecqa\"\n",
    ")\n",
    "\n",
    "trainer1 = Trainer(\n",
    "    model,\n",
    "    args1,\n",
    "    train_dataset=encoded_trecqa_train_ds,\n",
    "    eval_dataset=encoded_trecqa_valid_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer2 = Trainer(\n",
    "    model,\n",
    "    args2,\n",
    "    train_dataset=encoded_trecqa_train_ds,\n",
    "    eval_dataset=encoded_trecqa_test_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915d169c",
   "metadata": {},
   "source": [
    "#### evaluate without adapt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "78f8e8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a AlbertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='182' max='91' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [91/91 15:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3730306327342987,\n",
       " 'eval_mAP': 0.8733053307170918,\n",
       " 'eval_mRR': 0.9338235294117647,\n",
       " 'eval_runtime': 3.0004,\n",
       " 'eval_samples_per_second': 480.597,\n",
       " 'eval_steps_per_second': 30.329}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer2.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8daa6f",
   "metadata": {},
   "source": [
    "#### adapt then evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8a4ab0f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10017' max='10017' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10017/10017 14:10, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Map</th>\n",
       "      <th>Mrr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.141000</td>\n",
       "      <td>0.290266</td>\n",
       "      <td>0.926220</td>\n",
       "      <td>0.969231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.128500</td>\n",
       "      <td>0.335578</td>\n",
       "      <td>0.929783</td>\n",
       "      <td>0.969231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.108900</td>\n",
       "      <td>0.361455</td>\n",
       "      <td>0.922717</td>\n",
       "      <td>0.969231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10017, training_loss=0.13358091179858286, metrics={'train_runtime': 850.9625, 'train_samples_per_second': 188.317, 'train_steps_per_second': 11.771, 'total_flos': 682325065417320.0, 'train_loss': 0.13358091179858286, 'epoch': 3.0})"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer1.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8813d032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3183160722255707,\n",
       " 'eval_mAP': 0.9321352979936235,\n",
       " 'eval_mRR': 0.9926470588235294,\n",
       " 'eval_runtime': 3.1352,\n",
       " 'eval_samples_per_second': 459.939,\n",
       " 'eval_steps_per_second': 29.025}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer2.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0ecf34",
   "metadata": {},
   "source": [
    "### TESTING MODEL ROBUST-NESS\n",
    "\n",
    "- By incorrectly labeling a portion of the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e677777a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def inject_random_noise(df, noise_level=0.2):\n",
    "    noisy_df = df.copy()\n",
    "    num_samples_to_swap = int(len(noisy_df) * noise_level)\n",
    "    swap_indices = random.sample(range(len(noisy_df)), num_samples_to_swap)\n",
    "\n",
    "    for index in swap_indices:\n",
    "        row = noisy_df.iloc[index]\n",
    "        if row['label'] == 1:\n",
    "            noisy_df.at[index, 'label'] = 0\n",
    "        else:\n",
    "            noisy_df.at[index, 'label'] = 1\n",
    "    \n",
    "    return noisy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f5fab8",
   "metadata": {},
   "source": [
    "#### WikiQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1912461",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_wiki_qa_trainp = inject_random_noise(wiki_qa_trainp, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "897858cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    6336\n",
       "1    2315\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(noisy_wiki_qa_trainp['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ae15652b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    990\n",
       "1    136\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(wiki_qa_validationp['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6143ca95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    2058\n",
       "1     283\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(wiki_qa_testp['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7a2428dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiqa_train_ds = Dataset.from_pandas(noisy_wiki_qa_trainp)\n",
    "wikiqa_test_ds = Dataset.from_pandas(wiki_qa_testp)\n",
    "wikiqa_valid_ds = Dataset.from_pandas(wiki_qa_validationp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0a120644",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8651 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1126 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2341 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoints[model_name], use_fast=True)\n",
    "base_tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoints[model_name], num_labels=2)\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "encoded_train_dataset = wikiqa_train_ds.map(preprocess_function, batched=True)\n",
    "encoded_dev_dataset = wikiqa_valid_ds.map(preprocess_function, batched=True)\n",
    "encoded_test_dataset = wikiqa_test_ds.map(preprocess_function, batched=True)\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "args1 = TrainingArguments(\n",
    "    output_dir=f\"/scratch/kapilrk04/{model_name}_adapt_model_noisy_wikiqa\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=1e-6,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    include_inputs_for_metrics = True,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    fp16=False,\n",
    "    report_to=\"wandb\",\n",
    "    run_name=f\"tanda-{model_name}-eval-noisy-wikiqa\"\n",
    ")\n",
    "\n",
    "args2 = TrainingArguments(\n",
    "    output_dir=f\"/scratch/kapilrk04/{model_name}_adapt_base-model_noisy_wikiqa\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=1e-6,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    include_inputs_for_metrics = True,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    fp16=False,\n",
    "    report_to=\"wandb\",\n",
    "    run_name=f\"tanda-base-{model_name}-eval-noisy-wikiqa\"\n",
    ")\n",
    "\n",
    "\n",
    "trainer11 = Trainer(\n",
    "    base_model,\n",
    "    args1,\n",
    "    train_dataset=encoded_train_dataset,\n",
    "    eval_dataset=encoded_dev_dataset,\n",
    "    tokenizer=base_tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer12 = Trainer(\n",
    "    base_model,\n",
    "    args1,\n",
    "    train_dataset=encoded_train_dataset,\n",
    "    eval_dataset=encoded_test_dataset,\n",
    "    tokenizer=base_tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer21 = Trainer(\n",
    "    model,\n",
    "    args2,\n",
    "    train_dataset=encoded_train_dataset,\n",
    "    eval_dataset=encoded_dev_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer22 = Trainer(\n",
    "    model,\n",
    "    args2,\n",
    "    train_dataset=encoded_train_dataset,\n",
    "    eval_dataset=encoded_test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16dbc7e",
   "metadata": {},
   "source": [
    "#### baseline: adapt then evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "82ba6b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1623' max='1623' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1623/1623 06:14, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Map</th>\n",
       "      <th>Mrr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.604500</td>\n",
       "      <td>0.429044</td>\n",
       "      <td>0.711653</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.579700</td>\n",
       "      <td>0.420270</td>\n",
       "      <td>0.772019</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.569600</td>\n",
       "      <td>0.414159</td>\n",
       "      <td>0.784635</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1623, training_loss=0.5847777521176906, metrics={'train_runtime': 375.0453, 'train_samples_per_second': 69.2, 'train_steps_per_second': 4.327, 'total_flos': 956718047279160.0, 'train_loss': 0.5847777521176906, 'epoch': 3.0})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer11.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b47a663c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [147/147 00:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4125004708766937,\n",
       " 'eval_mAP': 0.7369086839768472,\n",
       " 'eval_mRR': 1.0,\n",
       " 'eval_runtime': 14.1411,\n",
       " 'eval_samples_per_second': 165.546,\n",
       " 'eval_steps_per_second': 10.395}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer12.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22c364c",
   "metadata": {},
   "source": [
    "#### transferred model - adapt then evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ebfd92ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1623' max='1623' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1623/1623 05:52, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Map</th>\n",
       "      <th>Mrr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.495800</td>\n",
       "      <td>0.427363</td>\n",
       "      <td>0.831214</td>\n",
       "      <td>0.922131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.784600</td>\n",
       "      <td>0.346172</td>\n",
       "      <td>0.829984</td>\n",
       "      <td>0.930328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.621500</td>\n",
       "      <td>0.343173</td>\n",
       "      <td>0.835418</td>\n",
       "      <td>0.930328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1623, training_loss=0.9382096512113467, metrics={'train_runtime': 352.8458, 'train_samples_per_second': 73.553, 'train_steps_per_second': 4.6, 'total_flos': 956408172344820.0, 'train_loss': 0.9382096512113467, 'epoch': 3.0})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer21.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d9010a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [147/147 00:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3063224256038666,\n",
       " 'eval_mAP': 0.8709468815149165,\n",
       " 'eval_mRR': 0.930379746835443,\n",
       " 'eval_runtime': 14.3847,\n",
       " 'eval_samples_per_second': 162.742,\n",
       " 'eval_steps_per_second': 10.219}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer22.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39083950",
   "metadata": {},
   "source": [
    "#### noise 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3b3330b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_wiki_qa_trainp = inject_random_noise(wiki_qa_trainp, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "78a71d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    6961\n",
       "1    1690\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(noisy_wiki_qa_trainp['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c04b6c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    990\n",
       "1    136\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(wiki_qa_validationp['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e2ac8e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    2058\n",
       "1     283\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(wiki_qa_testp['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f3282c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiqa_train_ds = Dataset.from_pandas(noisy_wiki_qa_trainp)\n",
    "wikiqa_test_ds = Dataset.from_pandas(wiki_qa_testp)\n",
    "wikiqa_valid_ds = Dataset.from_pandas(wiki_qa_validationp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eddba43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8651 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1126 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2341 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoints[model_name], use_fast=True)\n",
    "base_tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoints[model_name], num_labels=2)\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "encoded_train_dataset = wikiqa_train_ds.map(preprocess_function, batched=True)\n",
    "encoded_dev_dataset = wikiqa_valid_ds.map(preprocess_function, batched=True)\n",
    "encoded_test_dataset = wikiqa_test_ds.map(preprocess_function, batched=True)\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "args1 = TrainingArguments(\n",
    "    output_dir=f\"/scratch/kapilrk04/{model_name}_adapt_model_noisy_wikiqa\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=1e-6,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    include_inputs_for_metrics = True,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    fp16=False,\n",
    "    report_to=\"wandb\",\n",
    "    run_name=f\"tanda-{model_name}-eval-noisy-wikiqa\"\n",
    ")\n",
    "\n",
    "args2 = TrainingArguments(\n",
    "    output_dir=f\"/scratch/kapilrk04/{model_name}_adapt_base-model_noisy_wikiqa\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=1e-6,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    include_inputs_for_metrics = True,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    fp16=False,\n",
    "    report_to=\"wandb\",\n",
    "    run_name=f\"tanda-base-{model_name}-eval-noisy-wikiqa\"\n",
    ")\n",
    "\n",
    "\n",
    "trainer11 = Trainer(\n",
    "    base_model,\n",
    "    args1,\n",
    "    train_dataset=encoded_train_dataset,\n",
    "    eval_dataset=encoded_dev_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer12 = Trainer(\n",
    "    base_model,\n",
    "    args1,\n",
    "    train_dataset=encoded_train_dataset,\n",
    "    eval_dataset=encoded_test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer21 = Trainer(\n",
    "    model,\n",
    "    args2,\n",
    "    train_dataset=encoded_train_dataset,\n",
    "    eval_dataset=encoded_dev_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer22 = Trainer(\n",
    "    model,\n",
    "    args2,\n",
    "    train_dataset=encoded_train_dataset,\n",
    "    eval_dataset=encoded_test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cdefb3",
   "metadata": {},
   "source": [
    "#### baseline: adapt then evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "54f6091e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1623' max='1623' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1623/1623 06:13, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Map</th>\n",
       "      <th>Mrr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.586000</td>\n",
       "      <td>0.387771</td>\n",
       "      <td>0.631223</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.501200</td>\n",
       "      <td>0.378301</td>\n",
       "      <td>0.665638</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.487200</td>\n",
       "      <td>0.369738</td>\n",
       "      <td>0.714841</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1623, training_loss=0.5205584447911251, metrics={'train_runtime': 374.0775, 'train_samples_per_second': 69.379, 'train_steps_per_second': 4.339, 'total_flos': 956718047279160.0, 'train_loss': 0.5205584447911251, 'epoch': 3.0})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer11.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6d3d1146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [147/147 00:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3699658513069153,\n",
       " 'eval_mAP': 0.696794366238964,\n",
       " 'eval_mRR': 1.0,\n",
       " 'eval_runtime': 14.2596,\n",
       " 'eval_samples_per_second': 164.171,\n",
       " 'eval_steps_per_second': 10.309}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer12.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33869f3c",
   "metadata": {},
   "source": [
    "#### transferred model - adapt then evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "525eeb14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1623' max='1623' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1623/1623 06:13, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Map</th>\n",
       "      <th>Mrr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.083100</td>\n",
       "      <td>0.403032</td>\n",
       "      <td>0.854368</td>\n",
       "      <td>0.930328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.611800</td>\n",
       "      <td>0.308157</td>\n",
       "      <td>0.848005</td>\n",
       "      <td>0.934426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.494300</td>\n",
       "      <td>0.294762</td>\n",
       "      <td>0.849263</td>\n",
       "      <td>0.934426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1623, training_loss=0.7103453546266679, metrics={'train_runtime': 374.0044, 'train_samples_per_second': 69.392, 'train_steps_per_second': 4.34, 'total_flos': 956408172344820.0, 'train_loss': 0.7103453546266679, 'epoch': 3.0})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer21.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4799b49c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [147/147 00:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.2508821189403534,\n",
       " 'eval_mAP': 0.8874321327161139,\n",
       " 'eval_mRR': 0.9430379746835443,\n",
       " 'eval_runtime': 14.3184,\n",
       " 'eval_samples_per_second': 163.496,\n",
       " 'eval_steps_per_second': 10.266}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer22.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd19ff50",
   "metadata": {},
   "source": [
    "#### no noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "53e02dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    7632\n",
       "1    1019\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(wiki_qa_trainp['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4c0cba71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    990\n",
       "1    136\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(wiki_qa_validationp['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e4cbad11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    2058\n",
       "1     283\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(wiki_qa_testp['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bbe98776",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiqa_train_ds = Dataset.from_pandas(noisy_wiki_qa_trainp)\n",
    "wikiqa_test_ds = Dataset.from_pandas(wiki_qa_testp)\n",
    "wikiqa_valid_ds = Dataset.from_pandas(wiki_qa_validationp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "138b92a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8651 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1126 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2341 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoints[model_name], use_fast=True)\n",
    "base_tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoints[model_name], num_labels=2)\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "encoded_train_dataset = wikiqa_train_ds.map(preprocess_function, batched=True)\n",
    "encoded_dev_dataset = wikiqa_valid_ds.map(preprocess_function, batched=True)\n",
    "encoded_test_dataset = wikiqa_test_ds.map(preprocess_function, batched=True)\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "args1 = TrainingArguments(\n",
    "    output_dir=f\"/scratch/kapilrk04/{model_name}_adapt_model_noisy_wikiqa\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=1e-6,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    include_inputs_for_metrics = True,\n",
    "    num_train_epochs=6,\n",
    "    weight_decay=0.01,\n",
    "    fp16=False,\n",
    "    report_to=\"wandb\",\n",
    "    run_name=f\"tanda-{model_name}-eval-noisy-wikiqa\"\n",
    ")\n",
    "\n",
    "args2 = TrainingArguments(\n",
    "    output_dir=f\"/scratch/kapilrk04/{model_name}_adapt_base-model_noisy_wikiqa\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=1e-6,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    include_inputs_for_metrics = True,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    fp16=False,\n",
    "    report_to=\"wandb\",\n",
    "    run_name=f\"tanda-base-{model_name}-eval-noisy-wikiqa\"\n",
    ")\n",
    "\n",
    "\n",
    "trainer11 = Trainer(\n",
    "    base_model,\n",
    "    args1,\n",
    "    train_dataset=encoded_train_dataset,\n",
    "    eval_dataset=encoded_dev_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer12 = Trainer(\n",
    "    base_model,\n",
    "    args1,\n",
    "    train_dataset=encoded_train_dataset,\n",
    "    eval_dataset=encoded_test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer21 = Trainer(\n",
    "    model,\n",
    "    args2,\n",
    "    train_dataset=encoded_train_dataset,\n",
    "    eval_dataset=encoded_dev_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer22 = Trainer(\n",
    "    model,\n",
    "    args2,\n",
    "    train_dataset=encoded_train_dataset,\n",
    "    eval_dataset=encoded_test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1622b3",
   "metadata": {},
   "source": [
    "#### baseline: adapt then evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "98aac148",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3246' max='3246' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3246/3246 12:11, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Map</th>\n",
       "      <th>Mrr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.549100</td>\n",
       "      <td>0.372995</td>\n",
       "      <td>0.754844</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.485800</td>\n",
       "      <td>0.335937</td>\n",
       "      <td>0.815270</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.472000</td>\n",
       "      <td>0.321535</td>\n",
       "      <td>0.816307</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.461600</td>\n",
       "      <td>0.314001</td>\n",
       "      <td>0.822179</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.462300</td>\n",
       "      <td>0.311512</td>\n",
       "      <td>0.824567</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.462400</td>\n",
       "      <td>0.310747</td>\n",
       "      <td>0.824950</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3246, training_loss=0.480117595717265, metrics={'train_runtime': 731.4872, 'train_samples_per_second': 70.96, 'train_steps_per_second': 4.438, 'total_flos': 1911734608807740.0, 'train_loss': 0.480117595717265, 'epoch': 6.0})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer11.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2dd30686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [147/147 00:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.31764718890190125,\n",
       " 'eval_mAP': 0.8034285191941252,\n",
       " 'eval_mRR': 1.0,\n",
       " 'eval_runtime': 14.2891,\n",
       " 'eval_samples_per_second': 163.831,\n",
       " 'eval_steps_per_second': 10.288}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer12.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a49292",
   "metadata": {},
   "source": [
    "#### transferred model - adapt then evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "db4a35be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1623' max='1623' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1623/1623 05:52, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Map</th>\n",
       "      <th>Mrr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.495800</td>\n",
       "      <td>0.427363</td>\n",
       "      <td>0.831214</td>\n",
       "      <td>0.922131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.784600</td>\n",
       "      <td>0.346172</td>\n",
       "      <td>0.829984</td>\n",
       "      <td>0.930328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.621500</td>\n",
       "      <td>0.343173</td>\n",
       "      <td>0.835418</td>\n",
       "      <td>0.930328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1623, training_loss=0.9382096512113467, metrics={'train_runtime': 352.8458, 'train_samples_per_second': 73.553, 'train_steps_per_second': 4.6, 'total_flos': 956408172344820.0, 'train_loss': 0.9382096512113467, 'epoch': 3.0})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer21.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "11085d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [147/147 00:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3063224256038666,\n",
       " 'eval_mAP': 0.8709468815149165,\n",
       " 'eval_mRR': 0.930379746835443,\n",
       " 'eval_runtime': 14.3847,\n",
       " 'eval_samples_per_second': 162.742,\n",
       " 'eval_steps_per_second': 10.219}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer22.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
