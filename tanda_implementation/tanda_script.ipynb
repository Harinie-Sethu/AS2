{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE\n",
    "\n",
    "The code in this script is only partially done - it was an initial draft of the implementation. The implementation has since been fleshed out and moved to the Python files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6529dcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b8ef50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/scratch/kapilrk04/cache'\n",
    "os.environ['HF_DATASETS_CACHE']=\"/scratch/kapilrk04/cache\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0356abfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25b7c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d88071",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers datasets sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5094b628",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b069d56b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036717b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f263e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "asnq_dev = pd.read_csv(\"/home2/kapilrk04/anlp_proj/data_sets/asnq/dev.tsv\", sep=\"\\t\", names=[\"sentence1\", \"sentence2\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b20b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "asnq_dev[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07e16f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(asnq_dev[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfee340d",
   "metadata": {},
   "outputs": [],
   "source": [
    "asnq_train = pd.read_csv(\"/home2/kapilrk04/anlp_proj/data_sets/asnq/train.tsv\", sep=\"\\t\", names=[\"sentence1\", \"sentence2\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e61716f",
   "metadata": {},
   "outputs": [],
   "source": [
    "asnq_train[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4eab02",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(asnq_train[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b86d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainNeg = asnq_train[asnq_train['label']==3].sample(frac=0.25)\n",
    "trainNeg.loc[:,'label'] = 0\n",
    "trainPos = asnq_train[asnq_train['label']==4]\n",
    "trainPos.loc[:,'label'] = 1\n",
    "\n",
    "train_set = pd.concat([trainNeg, trainPos])\n",
    "train_set['idx'] = range(1, len(train_set) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a103f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1c5b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(train_set[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe943c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "devNeg = asnq_dev[asnq_dev['label']==3].sample(frac=0.25)\n",
    "devNeg.loc[:,'label'] = 0\n",
    "devPos = asnq_dev[asnq_dev['label']==4]\n",
    "devPos.loc[:,'label'] = 1\n",
    "\n",
    "dev_set = pd.concat([devNeg, devPos])\n",
    "dev_set['idx'] = range(1, len(dev_set) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3c70c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e3514a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(dev_set[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a019c203",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_set)\n",
    "dev_dataset = Dataset.from_pandas(dev_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2f50c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e81ceab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.remove_columns('__index_level_0__')\n",
    "dev_dataset = dev_dataset.remove_columns('__index_level_0__')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19c92a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d901661f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52829a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"sentence1\"], examples[\"sentence2\"], truncation=True)\n",
    "\n",
    "encoded_train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "encoded_dev_dataset = dev_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cb40b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dev_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1408763",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train_dataset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eefca1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d37ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "def split_array_by_number(arr, number):\n",
    "    result = []\n",
    "    current_split = []\n",
    "    \n",
    "    for item in arr:\n",
    "        if item == number:\n",
    "            if current_split:\n",
    "                result.append(current_split)\n",
    "                return current_split\n",
    "        else:\n",
    "            current_split.append(item)\n",
    "    if current_split:\n",
    "        result.append(current_split)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels, inputs = eval_pred\n",
    "    \n",
    "    splitnum = 0\n",
    "    if model_name == \"roberta-base\":\n",
    "        splitnum = 2\n",
    "    elif model_name == \"bert-base-uncased\":\n",
    "        splitnum = 102\n",
    "    elif model_name == \"albert-base-v2\":\n",
    "        splitnum = 3\n",
    "    elif model_name == \"distilbert-base-uncased\":\n",
    "        splitnum = 102\n",
    "\n",
    "    per_qn_inputs = {}\n",
    "\n",
    "    for i in range(len(inputs)):\n",
    "        split_inputs = split_array_by_number(inputs[i], splitnum)\n",
    "        qn = tuple(split_inputs)\n",
    "        if qn not in per_qn_inputs:\n",
    "            per_qn_inputs[qn] = {}\n",
    "            per_qn_inputs[qn][\"predictions\"] = []\n",
    "            per_qn_inputs[qn][\"labels\"] = []\n",
    "        per_qn_inputs[qn][\"predictions\"].append(predictions[i])\n",
    "        per_qn_inputs[qn][\"labels\"].append(labels[i])\n",
    "\n",
    "    avg_prec_scores = []\n",
    "    enc = OneHotEncoder(sparse=False)\n",
    "    labels = enc.fit_transform(np.array(labels).reshape(-1,1))\n",
    "\n",
    "    reciprocal_ranks = []\n",
    "\n",
    "    for qn in per_qn_inputs:\n",
    "        if per_qn_inputs[qn][\"labels\"].count(1) == 0 or per_qn_inputs[qn][\"labels\"].count(0) == 0:\n",
    "            continue\n",
    "        per_qn_inputs[qn]['predictions'] = np.array(per_qn_inputs[qn]['predictions'])\n",
    "        per_qn_inputs[qn]['labels'] = enc.fit_transform(np.array(per_qn_inputs[qn]['labels']).reshape(-1,1))\n",
    "        \n",
    "        #print(per_qn_inputs[qn]['predictions'], per_qn_inputs[qn]['labels'])\n",
    "        avg_prec_scores.append(average_precision_score(per_qn_inputs[qn][\"labels\"], per_qn_inputs[qn][\"predictions\"]))\n",
    "\n",
    "        true_label = per_qn_inputs[qn][\"labels\"]\n",
    "        pred_label = per_qn_inputs[qn][\"predictions\"]\n",
    "\n",
    "        sorted_pred_label = np.argsort(pred_label)[::-1]\n",
    "\n",
    "        for j in range(len(sorted_pred_label)):\n",
    "            row = sorted_pred_label[j]\n",
    "            rank = np.where(row == 1)[0]\n",
    "            if rank.size > 0:\n",
    "                reciprocal_ranks.append(1/(rank[0]+1))\n",
    "                break\n",
    "    \n",
    "    \n",
    "    map_score = np.mean(avg_prec_scores)\n",
    "    mrr_score = np.mean(reciprocal_ranks)\n",
    "\n",
    "    return {\n",
    "        \"mAP\" : map_score,\n",
    "        \"mRR\" : mrr_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0040c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train_dataset[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81c236e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"roberta-base\"\n",
    "batch_size = 16\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=f\"/scratch/kapilrk04/{model_name}_transfer_(epochs={9})\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    include_inputs_for_metrics = True,\n",
    "    num_train_epochs=9,\n",
    "    weight_decay=0.01,\n",
    "    fp16=False,\n",
    "    report_to=\"wandb\",\n",
    "    run_name=f\"{model_name}_transfer_(epochs={9})\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_train_dataset,\n",
    "    eval_dataset=encoded_dev_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
